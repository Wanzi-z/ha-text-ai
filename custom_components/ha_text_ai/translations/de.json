{
    "config": {
        "step": {
            "provider": {
                "title": "KI-Anbieter auswählen",
                "description": "Wählen Sie den KI-Dienst-Anbieter für diese Instanz",
                "data": {
                    "api_provider": "API-Anbieter"
                }
            },
            "user": {
                "title": "HA Text AI Instanz konfigurieren",
                "description": "Richten Sie eine neue KI-Assistenten-Instanz mit Ihrem ausgewählten Anbieter ein",
                "data": {
                    "name": "Instanzname (z.B. 'GPT Assistent', 'Claude Helfer')",
                    "api_key": "API-Schlüssel für Authentifizierung",
                    "model": "Zu verwendendes KI-Modell",
                    "temperature": "Antwort-Kreativität (0-2, niedriger = fokussierter)",
                    "max_tokens": "Maximale Antwortlänge (1-4096 Token)",
                    "api_endpoint": "Benutzerdefinierte API-Endpunkt-URL (optional)",
                    "request_interval": "Minimale Zeit zwischen Anfragen (0,1-60 Sekunden)"
                }
            }
        },
        "error": {
            "name_exists": "Eine Instanz mit diesem Namen existiert bereits",
            "invalid_name": "Ungültiger Instanzname",
            "invalid_auth": "Authentifizierung fehlgeschlagen - überprüfen Sie Ihren API-Schlüssel",
            "invalid_api_key": "Ungültiger API-Schlüssel - bitte überprüfen Sie Ihre Anmeldedaten",
            "cannot_connect": "Verbindung zum API-Dienst fehlgeschlagen",
            "invalid_model": "Ausgewähltes Modell ist nicht verfügbar",
            "rate_limit": "Anfragelimit überschritten",
            "context_length": "Kontextlänge überschritten",
            "rate_limit_exceeded": "API-Anfragelimit überschritten",
            "maintenance": "Dienst ist in Wartung",
            "invalid_response": "Ungültige API-Antwort erhalten",
            "api_error": "API-Dienst-Fehler aufgetreten",
            "timeout": "Anfrage-Zeitüberschreitung",
            "invalid_instance": "Ungültige Instanz angegeben",
            "unknown": "Unerwarteter Fehler aufgetreten"
        }
    },
    "options": {
        "step": {
            "init": {
                "title": "Instanzeinstellungen aktualisieren",
                "description": "Einstellungen für diese KI-Assistenten-Instanz ändern",
                "data": {
                    "model": "KI-Modell",
                    "temperature": "Antwort-Kreativität (0-2)",
                    "max_tokens": "Maximale Antwortlänge (1-4096)",
                    "request_interval": "Minimales Anfragen-Intervall (0,1-60 Sekunden)"
                }
            }
        }
    },
    "services": {
        "ask_question": {
            "name": "Frage stellen (HA Text AI)",
            "description": "Senden Sie eine Frage an das KI-Modell und erhalten Sie eine detaillierte Antwort. Die Antwort wird in der Gesprächshistorie gespeichert und kann später abgerufen werden.",
            "fields": {
                "instance": {
                    "name": "Instanz",
                    "description": "Name der zu verwendenden HA Text AI Instanz"
                },
                "question": {
                    "name": "Frage",
                    "description": "Ihre Frage oder Eingabeaufforderung für den KI-Assistenten"
                },
                "context_messages": {
                    "name": "Kontextnachrichten",
                    "description": "Anzahl der vorherigen Nachrichten, die in den Kontext einbezogen werden sollen (1-20)"
                },
                "system_prompt": {
                    "name": "Systemaufforderung",
                    "description": "Optionale Systemaufforderung zur Kontexteinstellung für diese spezifische Frage"
                },
                "model": {
                    "name": "Modell",
                    "description": "Wählen Sie das zu verwendende KI-Modell (optional, überschreibt Standardeinstellung)"
                },
                "temperature": {
                    "name": "Temperatur",
                    "description": "Steuert die Antwort-Kreativität (0,0-2,0)"
                },
                "max_tokens": {
                    "name": "Max. Token",
                    "description": "Maximale Länge der Antwort (1-4096 Token)"
                }
            }
        },
        "clear_history": {
            "name": "Verlauf löschen",
            "description": "Alle gespeicherten Fragen und Antworten aus dem Gesprächsverlauf löschen",
            "fields": {
                "instance": {
                    "name": "Instanz",
                    "description": "Name der HA Text AI Instanz, für die der Verlauf gelöscht werden soll"
                }
            }
        },
        "get_history": {
            "name": "Verlauf abrufen",
            "description": "Gesprächsverlauf mit optionaler Filterung und Sortierung abrufen",
            "fields": {
                "instance": {
                    "name": "Instanz",
                    "description": "Name der HA Text AI Instanz, aus der der Verlauf abgerufen werden soll"
                },
                "limit": {
                    "name": "Limit",
                    "description": "Anzahl der zurückzugebenden Gespräche (1-100)"
                },
                "filter_model": {
                    "name": "Modell filtern",
                    "description": "Gespräche nach bestimmtem KI-Modell filtern"
                },
                "start_date": {
                    "name": "Startdatum",
                    "description": "Gespräche ab diesem Datum/Zeitpunkt filtern"
                },
                "include_metadata": {
                    "name": "Metadaten einbeziehen",
                    "description": "Zusätzliche Informationen wie verwendete Token, Antwortzeit usw. einbeziehen"
                },
                "sort_order": {
                    "name": "Sortierreihenfolge",
                    "description": "Sortierreihenfolge der Ergebnisse (neueste oder älteste zuerst)"
                }
            }
        },
        "set_system_prompt": {
            "name": "Systemaufforderung festlegen",
            "description": "Standardmäßige Systemverhaltensinstruktionen für alle zukünftigen Gespräche festlegen",
            "fields": {
                "instance": {
                    "name": "Instanz",
                    "description": "Name der HA Text AI Instanz, für die die Systemaufforderung festgelegt werden soll"
                },
                "prompt": {
                    "name": "Systemaufforderung",
                    "description": "Anweisungen, die definieren, wie sich die KI verhalten und antworten soll"
                }
            }
        }
    },
    "entity": {
        "sensor": {
            "ha_text_ai": {
                "name": "{name}",
                "state": {
                    "ready": "Bereit",
                    "processing": "Verarbeitung",
                    "error": "Fehler",
                    "disconnected": "Getrennt",
                    "rate_limited": "Anfragelimit",
                    "maintenance": "Wartung",
                    "initializing": "Initialisierung",
                    "retrying": "Wiederholung",
                    "queued": "In Warteschlange"
                },
                "state_attributes": {
                    "question": {
                        "name": "Letzte Frage"
                    },
                    "response": {
                        "name": "Letzte Antwort"
                    },
                    "model": {
                        "name": "Aktuelles Modell"
                    },
                    "temperature": {
                        "name": "Temperatur"
                    },
                    "max_tokens": {
                        "name": "Max. Token"
                    },
                    "system_prompt": {
                        "name": "Systemaufforderung"
                    },
                    "response_time": {
                        "name": "Letzte Antwortzeit"
                    },
                    "total_responses": {
                        "name": "Gesamte Antworten"
                    },
                    "error_count": {
                        "name": "Fehleranzahl"
                    },
                    "last_error": {
                        "name": "Letzter Fehler"
                    },
                    "api_status": {
                        "name": "API-Status"
                    },
                    "tokens_used": {
                        "name": "Insgesamt verwendete Token"
                    },
                    "average_response_time": {
                        "name": "Durchschnittliche Antwortzeit"
                    },
                    "last_request_time": {
                        "name": "Letzte Anforderungszeit"
                    },
                    "is_processing": {
                        "name": "Verarbeitungsstatus"
                    },
                    "is_rate_limited": {
                        "name": "Status Anfragelimit"
                    },
                    "is_maintenance": {
                        "name": "Wartungsstatus"
                    },
                    "api_version": {
                        "name": "API-Version"
                    },
                    "endpoint_status": {
                        "name": "Endpunktstatus"
                    },
                    "performance_metrics": {
                        "name": "Leistungsmetriken"
                    },
                    "history_size": {
                        "name": "Verlaufsgröße"
                    },
                    "uptime": {
                        "name": "Betriebszeit"
                    },
                    "total_tokens": {
                        "name": "Gesamte Token"
                    },
                    "prompt_tokens": {
                        "name": "Prompt-Token"
                    },
                    "completion_tokens": {
                        "name": "Abschluss-Token"
                    },
                    "successful_requests": {
                        "name": "Erfolgreiche Anfragen"
                    },
                    "failed_requests": {
                        "name": "Fehlgeschlagene Anfragen"
                    },
                    "average_latency": {
                        "name": "Durchschnittliche Latenz"
                    },
                    "max_latency": {
                        "name": "Maximale Latenz"
                    },
                    "min_latency": {
                        "name": "Minimale Latenz"
                    }
                }
            }
        }
    }
}
