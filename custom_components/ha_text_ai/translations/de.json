{
  "metadata": {
      "author": "SMKRV",
      "license": "CC BY-NC-SA 4.0 International",
      "copyright": "© 2024"
  },  
  "config": {
    "step": {
      "provider": {
        "title": "KI-Anbieter auswählen",
        "description": "Wählen Sie den KI-Dienstanbieter für diese Instanz aus.",
        "data": {
          "api_provider": "API-Anbieter",
          "context_messages": "Anzahl der zu behaltenden Kontextnachrichten (1-20)"
        }
      },
      "user": {
        "title": "HA Text AI-Instanz konfigurieren",
        "description": "Richten Sie eine neue KI-Assistenteninstanz mit Ihrem ausgewählten Anbieter ein.",
        "data": {
          "name": "Instanzname (z. B. 'GPT-Assistent', 'Claude-Helfer')",
          "api_key": "API-Schlüssel zur Authentifizierung",
          "model": "Zu verwendendes KI-Modell",
          "temperature": "Antwortkreativität (0-2, niedriger = fokussierter)",
          "max_tokens": "Maximale Antwortlänge (1-4096 Token)",
          "api_endpoint": "Benutzerdefinierte API-Endpunkt-URL (optional)",
          "api_provider": "API-Anbieter",
          "request_interval": "Mindestzeit zwischen Anfragen (0,1-60 Sekunden)",
          "context_messages": "Anzahl der zu behaltenden Kontextnachrichten (1-20)",
          "max_history_size": "Maximale Größe des Konversationsverlaufs (1-100)"
        }
      }
    },
    "error": {
      "name_exists": "Eine Instanz mit diesem Namen existiert bereits",
      "invalid_name": "Ungültiger Instanzname",
      "invalid_auth": "Authentifizierung fehlgeschlagen - überprüfen Sie Ihren API-Schlüssel",
      "invalid_api_key": "Ungültiger API-Schlüssel - überprüfen Sie Ihre Anmeldedaten",
      "cannot_connect": "Verbindung zum API-Dienst fehlgeschlagen",
      "invalid_model": "Das ausgewählte Modell ist nicht verfügbar",
      "rate_limit": "Ratenlimit überschritten",
      "context_length": "Kontextlänge überschritten",
      "rate_limit_exceeded": "API-Ratenlimit überschritten",
      "maintenance": "Dienst befindet sich in der Wartung",
      "invalid_response": "Ungültige API-Antwort empfangen",
      "api_error": "Fehler im API-Dienst aufgetreten",
      "timeout": "Anfrage ist abgelaufen",
      "invalid_instance": "Ungültige Instanz angegeben",
      "unknown": "Es ist ein unerwarteter Fehler aufgetreten",
      "empty": "Name darf nicht leer sein",
      "invalid_characters": "Name darf nur Buchstaben, Zahlen, Leerzeichen, Unterstriche und Bindestriche enthalten",
      "name_too_long": "Name darf maximal 50 Zeichen lang sein"
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Instanzeinstellungen aktualisieren",
        "description": "Ändern Sie die Einstellungen für diese KI-Assistenteninstanz.",
        "data": {
          "model": "KI-Modell",
          "temperature": "Antwortkreativität (0-2)",
          "max_tokens": "Maximale Antwortlänge (1-4096)",
          "request_interval": "Mindestzeitraum zwischen Anfragen (0,1-60 Sekunden)",
          "context_messages": "Anzahl der vorherigen Nachrichten, die im Kontext enthalten sein sollen (1-20)",
          "max_history_size": "Maximale Größe des Konversationsverlaufs (1-100)"
        }
      }
    }
  },
  "services": {
    "ask_question": {
      "name": "Frage stellen (HA Text AI)",
      "description": "Senden Sie eine Frage an das KI-Modell und erhalten Sie eine detaillierte Antwort. Die Antwort wird im Konversationsverlauf gespeichert und kann später abgerufen werden.",
      "fields": {
        "instance": {
          "name": "Instanz",
          "description": "Name der zu verwendenden HA Text AI-Instanz"
        },
        "question": {
          "name": "Frage",
          "description": "Ihre Frage oder Aufforderung an den KI-Assistenten"
        },
        "context_messages": {
          "name": "Kontextnachrichten",
          "description": "Anzahl der vorherigen Nachrichten, die im Kontext enthalten sein sollen (1-20)"
        },
        "system_prompt": {
          "name": "Systemprompt",
          "description": "Optionaler Systemprompt, um den Kontext für diese spezielle Frage festzulegen"
        },
        "model": {
          "name": "Modell",
          "description": "Wählen Sie das zu verwendende KI-Modell aus (optional, überschreibt die Standardeinstellung)"
        },
        "temperature": {
          "name": "Temperatur",
          "description": "Steuert die Antwortkreativität (0.0-2.0)"
        },
        "max_tokens": {
          "name": "Max. Token",
          "description": "Maximale Länge der Antwort (1-4096 Token)"
        }
      }
    },
    "clear_history": {
      "name": "Verlauf löschen",
      "description": "Alle gespeicherten Fragen und Antworten aus dem Konversationsverlauf löschen",
      "fields": {
        "instance": {
          "name": "Instanz",
          "description": "Name der HA Text AI-Instanz, deren Verlauf gelöscht werden soll"
        }
      }
    },
    "get_history": {
      "name": "Verlauf abrufen",
      "description": "Konversationsverlauf mit optionalem Filtern und Sortieren abrufen",
      "fields": {
        "instance": {
          "name": "Instanz",
          "description": "Name der HA Text AI-Instanz, von der der Verlauf abgerufen werden soll"
        },
        "limit": {
          "name": "Limit",
          "description": "Anzahl der zurückzugebenden Konversationen (1-100)"
        },
        "filter_model": {
          "name": "Modell filtern",
          "description": "Konversationen nach einem bestimmten KI-Modell filtern"
        },
        "start_date": {
          "name": "Startdatum",
          "description": "Konversationen ab diesem Datum/Uhrzeit filtern"
        },
        "include_metadata": {
          "name": "Metadaten einschließen",
          "description": "Zusätzliche Informationen wie verwendete Token, Antwortzeit usw. einschließen"
        },
        "sort_order": {
          "name": "Sortierreihenfolge",
          "description": "Sortierreihenfolge für die Ergebnisse (neueste oder älteste zuerst)"
        }
      }
    },
    "set_system_prompt": {
      "name": "Systemprompt festlegen",
      "description": "Legen Sie Standardanweisungen für das Systemverhalten für alle zukünftigen Konversationen fest",
      "fields": {
        "instance": {
          "name": "Instanz",
          "description": "Name der HA Text AI-Instanz, für die der Systemprompt festgelegt werden soll"
        },
        "prompt": {
          "name": "Systemprompt",
          "description": "Anweisungen, die definieren, wie sich die KI verhalten und antworten soll"
        }
      }
    }
  },
  "entity": {
    "sensor": {
      "ha_text_ai": {
        "name": "{name}",
        "state": {
          "ready": "Bereit",
          "processing": "Verarbeitung",
          "error": "Fehler",
          "disconnected": "Getrennt",
          "rate_limited": "Ratenlimit",
          "maintenance": "Wartung",
          "initializing": "Initialisierung",
          "retrying": "Wiederholen",
          "queued": "Warteschlange"
        },
        "state_attributes": {
          "question": {
            "name": "Letzte Frage"
          },
          "response": {
            "name": "Letzte Antwort"
          },
          "model": {
            "name": "Aktuelles Modell"
          },
          "temperature": {
            "name": "Temperatur"
          },
          "max_tokens": {
            "name": "Max. Token"
          },
          "system_prompt": {
            "name": "Systemprompt"
          },
          "response_time": {
            "name": "Letzte Antwortzeit"
          },
          "total_responses": {
            "name": "Gesamtzahl der Antworten"
          },
          "error_count": {
            "name": "Fehleranzahl"
          },
          "last_error": {
            "name": "Letzter Fehler"
          },
          "api_status": {
            "name": "API-Status"
          },
          "tokens_used": {
            "name": "Verwendete Token insgesamt"
          },
          "average_response_time": {
            "name": "Durchschnittliche Antwortzeit"
          },
          "last_request_time": {
            "name": "Zeitpunkt der letzten Anfrage"
          },
          "is_processing": {
            "name": "Verarbeitungsstatus"
          },
          "is_rate_limited": {
            "name": "Ratenlimit-Status"
          },
          "is_maintenance": {
            "name": "Wartungsstatus"
          },
          "api_version": {
            "name": "API-Version"
          },
          "endpoint_status": {
            "name": "Endpunkt-Status"
          },
          "performance_metrics": {
            "name": "Leistungsmetriken"
          },
          "history_size": {
            "name": "Verlaufsgröße"
          },
          "uptime": {
            "name": "Betriebszeit"
          },
          "total_tokens": {
            "name": "Gesamtzahl der Token"
          },
          "prompt_tokens": {
            "name": "Prompt-Token"
          },
          "completion_tokens": {
            "name": "Completion-Token"
          },
          "successful_requests": {
            "name": "Erfolgreiche Anfragen"
          },
          "failed_requests": {
            "name": "Fehlgeschlagene Anfragen"
          },
          "average_latency": {
            "name": "Durchschnittliche Latenz"
          },
          "max_latency": {
            "name": "Maximale Latenz"
          },
          "min_latency": {
            "name": "Minimale Latenz"
          }
        }
      }
    }
  }
}
